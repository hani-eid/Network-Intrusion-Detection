{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"bg\" style=\"height:150px;width:150px; float=left; clear=true; margin-left:35%\">\n",
    "  <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/ce/IE_University_logo.svg/1200px-IE_University_logo.svg.png\" style=\"width:100%; height:100%;\">\n",
    "</div> \n",
    " \n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f3/Apache_Spark_logo.svg/1280px-Apache_Spark_logo.svg.png\" style=\"width:10%; height:10%; margin-left:37%\">\n",
    "\n",
    "## <span style=\"color:black; margin-left:26%; font-size:16pt;\">Professor: Asier Abreu Aramburu</span>\n",
    "## <span style=\"color:red; margin-left:15%; font-size:22pt;\"><u>Challenge #1: Network Intrusion Detection</u></span>\n",
    "</br>\n",
    "</br>\n",
    "</br>\n",
    "\n",
    "## Team Members:\n",
    "    1. Resham Gala\n",
    "    2. Mike Tondu\n",
    "    3. Mustafa Demir\n",
    "    4. Nacho\n",
    "    5. Dan Ryan\n",
    "    6. Sina\n",
    "    7. Hani Eid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries and setting dataset path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "my_home=os.environ['HOME']\n",
    "dataset_path=\"/home/ubuntu/spark-course/FinalProject/challenge_1/\"\n",
    "outputs_path=my_home\n",
    "#import findspark\n",
    "#findspark.init()\n",
    "#i have commented this since i ran this locally on the vm, if cluster is working for you then uncomment this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark #for the vm only\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSessiont\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[1]\") \\\n",
    "    .appName(\"GroupProject-TeamE-ML\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"2g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data:\n",
    "    1. full.data\n",
    "    2. Corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(\"file://\"+dataset_path+\"full.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test_1 = spark.read \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(\"file://\"+dataset_path+\"corrected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing column names based on names text file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features=[  \"duration\",\"protocol_type\",\"service\", \\\n",
    "            \"flag\",\"src_bytes\",\"dst_bytes\", \\\n",
    "            \"land\",\"wrong_fragment\",\"urgent\", \\\n",
    "            \"hot\",\"num_failed_logins\",\"logged_in\", \\\n",
    "            \"num_compromised\",\"root_shell\",\"su_attempted\", \\\n",
    "            \"num_root\",\"num_file\",\"num_shells\",\"num_access_files\", \\\n",
    "            \"num_outbound_cmds\",\"is_host_login\",\"is_guest_login\", \\\n",
    "            \"count\",\"srv_count\",\"serror_rate\",\"srv_serror_rate\", \\\n",
    "            \"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\", \\\n",
    "            \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\", \\\n",
    "            \"dst_host_srv_count\",\"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\", \\\n",
    "            \"dst_host_same_src_port_rate\",\"dst_host_srv_diff_host_rate\", \\\n",
    "            \"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\"dst_host_rerror_rate\", \\\n",
    "            \"dst_host_srv_rerror_rate\",\"connection_type\"]\n",
    "\n",
    "rawnames=df.schema.names\n",
    "\n",
    "# Create a small function\n",
    "def updateColNames(df,oldnames,newnames):\n",
    "    for i in range(len(newnames)):\n",
    "        df=df.withColumnRenamed(oldnames[i], newnames[i])\n",
    "    return df\n",
    "\n",
    "df=updateColNames(df,rawnames,features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = updateColNames(df_test_1,rawnames,features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- protocol_type: string (nullable = true)\n",
      " |-- service: string (nullable = true)\n",
      " |-- flag: string (nullable = true)\n",
      " |-- src_bytes: integer (nullable = true)\n",
      " |-- dst_bytes: integer (nullable = true)\n",
      " |-- land: integer (nullable = true)\n",
      " |-- wrong_fragment: integer (nullable = true)\n",
      " |-- urgent: integer (nullable = true)\n",
      " |-- hot: integer (nullable = true)\n",
      " |-- num_failed_logins: integer (nullable = true)\n",
      " |-- logged_in: integer (nullable = true)\n",
      " |-- num_compromised: integer (nullable = true)\n",
      " |-- root_shell: integer (nullable = true)\n",
      " |-- su_attempted: integer (nullable = true)\n",
      " |-- num_root: integer (nullable = true)\n",
      " |-- num_file: integer (nullable = true)\n",
      " |-- num_shells: integer (nullable = true)\n",
      " |-- num_access_files: integer (nullable = true)\n",
      " |-- num_outbound_cmds: integer (nullable = true)\n",
      " |-- is_host_login: integer (nullable = true)\n",
      " |-- is_guest_login: integer (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      " |-- srv_count: integer (nullable = true)\n",
      " |-- serror_rate: double (nullable = true)\n",
      " |-- srv_serror_rate: double (nullable = true)\n",
      " |-- rerror_rate: double (nullable = true)\n",
      " |-- srv_rerror_rate: double (nullable = true)\n",
      " |-- same_srv_rate: double (nullable = true)\n",
      " |-- diff_srv_rate: double (nullable = true)\n",
      " |-- srv_diff_host_rate: double (nullable = true)\n",
      " |-- dst_host_count: integer (nullable = true)\n",
      " |-- dst_host_srv_count: integer (nullable = true)\n",
      " |-- dst_host_same_srv_rate: double (nullable = true)\n",
      " |-- dst_host_diff_srv_rate: double (nullable = true)\n",
      " |-- dst_host_same_src_port_rate: double (nullable = true)\n",
      " |-- dst_host_srv_diff_host_rate: double (nullable = true)\n",
      " |-- dst_host_serror_rate: double (nullable = true)\n",
      " |-- dst_host_srv_serror_rate: double (nullable = true)\n",
      " |-- dst_host_rerror_rate: double (nullable = true)\n",
      " |-- dst_host_srv_rerror_rate: double (nullable = true)\n",
      " |-- connection_type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the current schema of the dataset\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('service').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(service='telnet'),\n",
       " Row(service='ftp'),\n",
       " Row(service='auth'),\n",
       " Row(service='iso_tsap'),\n",
       " Row(service='systat'),\n",
       " Row(service='name'),\n",
       " Row(service='sql_net'),\n",
       " Row(service='ntp_u'),\n",
       " Row(service='X11'),\n",
       " Row(service='pop_3'),\n",
       " Row(service='ldap'),\n",
       " Row(service='discard'),\n",
       " Row(service='tftp_u'),\n",
       " Row(service='Z39_50'),\n",
       " Row(service='daytime'),\n",
       " Row(service='domain_u'),\n",
       " Row(service='login'),\n",
       " Row(service='smtp'),\n",
       " Row(service='http_2784'),\n",
       " Row(service='mtp'),\n",
       " Row(service='domain'),\n",
       " Row(service='http'),\n",
       " Row(service='harvest'),\n",
       " Row(service='link'),\n",
       " Row(service='courier'),\n",
       " Row(service='kshell'),\n",
       " Row(service='pop_2'),\n",
       " Row(service='other'),\n",
       " Row(service='exec'),\n",
       " Row(service='nnsp'),\n",
       " Row(service='efs'),\n",
       " Row(service='IRC'),\n",
       " Row(service='pm_dump'),\n",
       " Row(service='private'),\n",
       " Row(service='urh_i'),\n",
       " Row(service='ftp_data'),\n",
       " Row(service='whois'),\n",
       " Row(service='nntp'),\n",
       " Row(service='netbios_ns'),\n",
       " Row(service='aol'),\n",
       " Row(service='klogin'),\n",
       " Row(service='shell'),\n",
       " Row(service='red_i'),\n",
       " Row(service='tim_i'),\n",
       " Row(service='uucp_path'),\n",
       " Row(service='eco_i'),\n",
       " Row(service='ctf'),\n",
       " Row(service='vmnet'),\n",
       " Row(service='supdup'),\n",
       " Row(service='http_8001'),\n",
       " Row(service='finger'),\n",
       " Row(service='netbios_dgm'),\n",
       " Row(service='printer'),\n",
       " Row(service='urp_i'),\n",
       " Row(service='ecr_i'),\n",
       " Row(service='time'),\n",
       " Row(service='netbios_ssn'),\n",
       " Row(service='csnet_ns'),\n",
       " Row(service='hostnames'),\n",
       " Row(service='sunrpc'),\n",
       " Row(service='echo'),\n",
       " Row(service='http_443'),\n",
       " Row(service='netstat'),\n",
       " Row(service='gopher'),\n",
       " Row(service='remote_job'),\n",
       " Row(service='imap4'),\n",
       " Row(service='uucp'),\n",
       " Row(service='ssh'),\n",
       " Row(service='rje'),\n",
       " Row(service='bgp')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('service').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.select('protocol_type').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.select('connection_type').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categoricalColumns = [\"protocol_type\", \"service\", \"flag\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We check for level of all categorical variables in both training and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ protocol_type ] : 3\n",
      "[ service ] : 70\n",
      "[ flag ] : 11\n"
     ]
    }
   ],
   "source": [
    "for col in categoricalColumns:\n",
    "    print(\"[\", col,\"] :\", df.select(col).distinct().count())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ protocol_type ] : 3\n",
      "[ service ] : 65\n",
      "[ flag ] : 11\n"
     ]
    }
   ],
   "source": [
    "for col in categoricalColumns:\n",
    "    print(\"[\",col,\"] :\",df_test.select(col).distinct().count())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We observe that the 'service' variable has more classes in the training set, so thats why we merge them together for data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Nb. of records  : %d' % df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#defining the target variable\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "df = df.withColumn('label',when(df.connection_type == 'normal.', 0).otherwise(1))\n",
    "df_test = df_test.withColumn('label',when(df_test.connection_type == 'normal.',0).otherwise(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.stat import Correlation\n",
    "def computeCorrelation(df,targetColumnName):\n",
    "    corDF = pd.DataFrame(columns=['Target','Ind','Value'])\n",
    "    ind = 0\n",
    "    for col in df.columns:\n",
    "        r=df.stat.corr(col,targetColumnName)\n",
    "        x = [targetColumnName, col,r]\n",
    "        corDF = corDF.set_value(ind, corDF.columns, x)\n",
    "        ind = ind + 1\n",
    "        #print(\"Pearson correlation : %s %s %f \\n\" %(col,targetColumnName,r))\n",
    "    \n",
    "    return corDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numericDf = df.drop('service', 'protocol_type', 'flag', 'connection_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corMatrix = computeCorrelation(numericDf, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Ind</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>label</td>\n",
       "      <td>label</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>label</td>\n",
       "      <td>count</td>\n",
       "      <td>0.767425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>label</td>\n",
       "      <td>dst_host_count</td>\n",
       "      <td>0.656897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>label</td>\n",
       "      <td>srv_count</td>\n",
       "      <td>0.575426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>label</td>\n",
       "      <td>dst_host_same_src_port_rate</td>\n",
       "      <td>0.486541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>label</td>\n",
       "      <td>dst_host_srv_serror_rate</td>\n",
       "      <td>0.230333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>label</td>\n",
       "      <td>serror_rate</td>\n",
       "      <td>0.230061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>label</td>\n",
       "      <td>srv_serror_rate</td>\n",
       "      <td>0.229606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>label</td>\n",
       "      <td>dst_host_serror_rate</td>\n",
       "      <td>0.229516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>label</td>\n",
       "      <td>diff_srv_rate</td>\n",
       "      <td>0.0159138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>label</td>\n",
       "      <td>wrong_fragment</td>\n",
       "      <td>0.00753623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>label</td>\n",
       "      <td>rerror_rate</td>\n",
       "      <td>0.00369595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>label</td>\n",
       "      <td>dst_host_srv_rerror_rate</td>\n",
       "      <td>0.00354277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>label</td>\n",
       "      <td>srv_rerror_rate</td>\n",
       "      <td>0.00326006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>label</td>\n",
       "      <td>dst_host_rerror_rate</td>\n",
       "      <td>0.000309032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>label</td>\n",
       "      <td>src_bytes</td>\n",
       "      <td>0.00018865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>label</td>\n",
       "      <td>land</td>\n",
       "      <td>-0.000308099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>label</td>\n",
       "      <td>is_host_login</td>\n",
       "      <td>-0.00128362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>label</td>\n",
       "      <td>dst_bytes</td>\n",
       "      <td>-0.00165236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>label</td>\n",
       "      <td>urgent</td>\n",
       "      <td>-0.00193304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>label</td>\n",
       "      <td>num_compromised</td>\n",
       "      <td>-0.00391122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>label</td>\n",
       "      <td>num_failed_logins</td>\n",
       "      <td>-0.0045443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>label</td>\n",
       "      <td>num_root</td>\n",
       "      <td>-0.0065776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>label</td>\n",
       "      <td>su_attempted</td>\n",
       "      <td>-0.00906986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>label</td>\n",
       "      <td>root_shell</td>\n",
       "      <td>-0.0146054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>label</td>\n",
       "      <td>num_shells</td>\n",
       "      <td>-0.0164402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>label</td>\n",
       "      <td>num_file</td>\n",
       "      <td>-0.0188338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>label</td>\n",
       "      <td>hot</td>\n",
       "      <td>-0.0393773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>label</td>\n",
       "      <td>is_guest_login</td>\n",
       "      <td>-0.0524985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>label</td>\n",
       "      <td>num_access_files</td>\n",
       "      <td>-0.0576083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>label</td>\n",
       "      <td>dst_host_srv_count</td>\n",
       "      <td>-0.0601634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>label</td>\n",
       "      <td>dst_host_same_srv_rate</td>\n",
       "      <td>-0.110369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>label</td>\n",
       "      <td>duration</td>\n",
       "      <td>-0.116638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>label</td>\n",
       "      <td>dst_host_diff_srv_rate</td>\n",
       "      <td>-0.118273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>label</td>\n",
       "      <td>dst_host_srv_diff_host_rate</td>\n",
       "      <td>-0.215675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>label</td>\n",
       "      <td>same_srv_rate</td>\n",
       "      <td>-0.249826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>label</td>\n",
       "      <td>srv_diff_host_rate</td>\n",
       "      <td>-0.369147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>label</td>\n",
       "      <td>logged_in</td>\n",
       "      <td>-0.817431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>label</td>\n",
       "      <td>num_outbound_cmds</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target                          Ind        Value\n",
       "38  label                        label            1\n",
       "19  label                        count     0.767425\n",
       "28  label               dst_host_count     0.656897\n",
       "20  label                    srv_count     0.575426\n",
       "32  label  dst_host_same_src_port_rate     0.486541\n",
       "35  label     dst_host_srv_serror_rate     0.230333\n",
       "21  label                  serror_rate     0.230061\n",
       "22  label              srv_serror_rate     0.229606\n",
       "34  label         dst_host_serror_rate     0.229516\n",
       "26  label                diff_srv_rate    0.0159138\n",
       "4   label               wrong_fragment   0.00753623\n",
       "23  label                  rerror_rate   0.00369595\n",
       "37  label     dst_host_srv_rerror_rate   0.00354277\n",
       "24  label              srv_rerror_rate   0.00326006\n",
       "36  label         dst_host_rerror_rate  0.000309032\n",
       "1   label                    src_bytes   0.00018865\n",
       "3   label                         land -0.000308099\n",
       "17  label                is_host_login  -0.00128362\n",
       "2   label                    dst_bytes  -0.00165236\n",
       "5   label                       urgent  -0.00193304\n",
       "9   label              num_compromised  -0.00391122\n",
       "7   label            num_failed_logins   -0.0045443\n",
       "12  label                     num_root   -0.0065776\n",
       "11  label                 su_attempted  -0.00906986\n",
       "10  label                   root_shell   -0.0146054\n",
       "14  label                   num_shells   -0.0164402\n",
       "13  label                     num_file   -0.0188338\n",
       "6   label                          hot   -0.0393773\n",
       "18  label               is_guest_login   -0.0524985\n",
       "15  label             num_access_files   -0.0576083\n",
       "29  label           dst_host_srv_count   -0.0601634\n",
       "30  label       dst_host_same_srv_rate    -0.110369\n",
       "0   label                     duration    -0.116638\n",
       "31  label       dst_host_diff_srv_rate    -0.118273\n",
       "33  label  dst_host_srv_diff_host_rate    -0.215675\n",
       "25  label                same_srv_rate    -0.249826\n",
       "27  label           srv_diff_host_rate    -0.369147\n",
       "8   label                    logged_in    -0.817431\n",
       "16  label            num_outbound_cmds          NaN"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corMatrix.sort_values(by=['Value'],  ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Creating a new data frame containing both training and test for later transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mixedDS = df.union(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>connection_type</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>45076</td>\n",
       "      <td>normal.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>4528</td>\n",
       "      <td>normal.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>1228</td>\n",
       "      <td>normal.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>2032</td>\n",
       "      <td>normal.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>486</td>\n",
       "      <td>normal.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>1282</td>\n",
       "      <td>normal.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>1337</td>\n",
       "      <td>normal.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>1364</td>\n",
       "      <td>normal.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>1295</td>\n",
       "      <td>normal.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>5450</td>\n",
       "      <td>normal.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  protocol_type service  dst_bytes connection_type  label\n",
       "0           tcp    http      45076         normal.      0\n",
       "1           tcp    http       4528         normal.      0\n",
       "2           tcp    http       1228         normal.      0\n",
       "3           tcp    http       2032         normal.      0\n",
       "4           tcp    http        486         normal.      0\n",
       "5           tcp    http       1282         normal.      0\n",
       "6           tcp    http       1337         normal.      0\n",
       "7           tcp    http       1364         normal.      0\n",
       "8           tcp    http       1295         normal.      0\n",
       "9           tcp    http       5450         normal.      0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixedDS.select('protocol_type', 'service', 'dst_bytes', 'connection_type', 'label').limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Forming the pipeline stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "\n",
    "stages = [] # stages in our Pipeline\n",
    "for col in categoricalColumns:\n",
    "  \n",
    "  # Category Indexing with StringIndexer\n",
    "  indexer = StringIndexer(inputCol=col, outputCol=col+\"_index\")\n",
    "  #indexer.setHandleInvalid(\"skip\")\n",
    "    \n",
    "  # Use OneHotEncoder to convert categorical variables into binary SparseVectors\n",
    "  encoder = OneHotEncoder(inputCol=col+\"_index\", outputCol=col+\"_vector\")\n",
    " \n",
    "  # Add stages.  These are not run here, but will run all at once later on.\n",
    "  stages += [indexer, encoder]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Defining different data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = [\"label\"]\n",
    "numericCols = ['count', 'dst_host_count', 'srv_count', 'dst_host_same_src_port_rate', 'logged_in']\n",
    "#numericCols = [\"duration\", \"src_bytes\", \"dst_bytes\", \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\", \"num_compromised\", \"num_root\", \"num_file\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\"count\",\"serror_rate\",\"rerror_rate\",\"same_srv_rate\",\"diff_srv_rate\",\"srv_count\",\"srv_serror_rate\",\"srv_rerror_rate\",\"srv_diff_host_rate\"] # you can add extra features if you want, i have not considered all\n",
    "binaryCols = [\"logged_in\",\"root_shell\",\"su_attempted\",\"is_host_login\",\"is_guest_login\"] #not standardizing this as  it is just 0/1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Transform all numerical features into a vector using VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assemblerInputs = [ col + \"_vector\" for col in categoricalColumns ] + numericCols + binaryCols\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_4dc8ad6fa038118252e4,\n",
       " OneHotEncoder_4be6bfbc8a9bf98be0ce,\n",
       " StringIndexer_4414bcf864926cc18608,\n",
       " OneHotEncoder_4d00bd904a2036c70523,\n",
       " StringIndexer_492088f14bcedde14be2,\n",
       " OneHotEncoder_4b0ab7f00d516eca2900,\n",
       " VectorAssembler_420a8950ba919f70df60]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Applying the pipeline stages on the Mixed Union Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Transformation of the test set\n",
    "from pyspark.ml import Pipeline\n",
    "# Create a Pipeline.\n",
    "pipeline = Pipeline(stages=stages)\n",
    "\n",
    "# Run the feature transformations.\n",
    "#  - fit() computes feature statistics as needed.\n",
    "#  - transform() actually transforms the features.\n",
    "\n",
    "transformer_test = pipeline.fit(mixedDS)\n",
    "transformed_df_Mixed = transformer_test.transform(mixedDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Creating a new column (autoincremental) ID for splitting the Merged Dataset back to Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "# This will return a new DF with all the columns + id\n",
    "transformed_df_Mixed = transformed_df_Mixed.withColumn(\"id\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformed_df_Mixed.createOrReplaceTempView(\"Mixed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformed_df_Mixed = transformed_df_Mixed.select(\"features\", \"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. ReCreating the Training set from the Mixed table view created earlier using SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_new = spark.sql(\"select * from Mixed Limit 4898431\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>connection_type</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>45076</td>\n",
       "      <td>normal.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>4528</td>\n",
       "      <td>normal.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>1228</td>\n",
       "      <td>normal.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>2032</td>\n",
       "      <td>normal.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>486</td>\n",
       "      <td>normal.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>1282</td>\n",
       "      <td>normal.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>1337</td>\n",
       "      <td>normal.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>1364</td>\n",
       "      <td>normal.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>1295</td>\n",
       "      <td>normal.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>5450</td>\n",
       "      <td>normal.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  protocol_type service  dst_bytes connection_type  label\n",
       "0           tcp    http      45076         normal.      0\n",
       "1           tcp    http       4528         normal.      0\n",
       "2           tcp    http       1228         normal.      0\n",
       "3           tcp    http       2032         normal.      0\n",
       "4           tcp    http        486         normal.      0\n",
       "5           tcp    http       1282         normal.      0\n",
       "6           tcp    http       1337         normal.      0\n",
       "7           tcp    http       1364         normal.      0\n",
       "8           tcp    http       1295         normal.      0\n",
       "9           tcp    http       5450         normal.      0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new.select('protocol_type', 'service', 'dst_bytes', 'connection_type', 'label').limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. ReCreating the Test set from the Mixed table view created earlier using SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_new = spark.sql(\"select * from Mixed order by id desc Limit 311029\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>connection_type</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>udp</td>\n",
       "      <td>private</td>\n",
       "      <td>147</td>\n",
       "      <td>normal.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>udp</td>\n",
       "      <td>private</td>\n",
       "      <td>147</td>\n",
       "      <td>normal.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>udp</td>\n",
       "      <td>private</td>\n",
       "      <td>147</td>\n",
       "      <td>normal.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>udp</td>\n",
       "      <td>private</td>\n",
       "      <td>147</td>\n",
       "      <td>normal.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>udp</td>\n",
       "      <td>private</td>\n",
       "      <td>147</td>\n",
       "      <td>normal.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>udp</td>\n",
       "      <td>private</td>\n",
       "      <td>105</td>\n",
       "      <td>snmpgetattack.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>udp</td>\n",
       "      <td>private</td>\n",
       "      <td>105</td>\n",
       "      <td>normal.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>udp</td>\n",
       "      <td>private</td>\n",
       "      <td>105</td>\n",
       "      <td>snmpgetattack.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>udp</td>\n",
       "      <td>private</td>\n",
       "      <td>105</td>\n",
       "      <td>normal.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>udp</td>\n",
       "      <td>private</td>\n",
       "      <td>105</td>\n",
       "      <td>snmpgetattack.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  protocol_type  service  dst_bytes connection_type  label\n",
       "0           udp  private        147         normal.      0\n",
       "1           udp  private        147         normal.      0\n",
       "2           udp  private        147         normal.      0\n",
       "3           udp  private        147         normal.      0\n",
       "4           udp  private        147         normal.      0\n",
       "5           udp  private        105  snmpgetattack.      1\n",
       "6           udp  private        105         normal.      0\n",
       "7           udp  private        105  snmpgetattack.      1\n",
       "8           udp  private        105         normal.      0\n",
       "9           udp  private        105  snmpgetattack.      1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_new.select('protocol_type', 'service', 'dst_bytes', 'connection_type', 'label').limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_new = train_new.select(\"features\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_new = test_new.select(\"features\", \"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Caching both training and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[features: vector, label: int]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[features: vector, label: int]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_new.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Training Data for Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training records : 3427914\n",
      "Test records : 1470517 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[features: vector, label: int]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This takes rather long for some reason (train test split takes long)\n",
    "### Randomly split data into training (70%) and test (30%) sets. set seed for reproducibility\n",
    "(train_data, test_data) = train_new.randomSplit([0.7, 0.3])\n",
    "print('Training records : %d' % train_data.count())\n",
    "print('Test records : %d ' % test_data.count())\n",
    "train_data.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing a Logistic Regression on CV Train Data (Splitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Create initial LogisticRegression model\n",
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10)\n",
    "\n",
    "# Train model with Training Data\n",
    "model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting on CV Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>label</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.271559052145, -0.271559052145]</td>\n",
       "      <td>[0.567475609885, 0.432524390115]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.271559052145, -0.271559052145]</td>\n",
       "      <td>[0.567475609885, 0.432524390115]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.271559052145, -0.271559052145]</td>\n",
       "      <td>[0.567475609885, 0.432524390115]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.271559052145, -0.271559052145]</td>\n",
       "      <td>[0.567475609885, 0.432524390115]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.271559052145, -0.271559052145]</td>\n",
       "      <td>[0.567475609885, 0.432524390115]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            features  label  \\\n",
       "0  (1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      0   \n",
       "1  (1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      0   \n",
       "2  (1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      0   \n",
       "3  (1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      1   \n",
       "4  (1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      1   \n",
       "\n",
       "                       rawPrediction                       probability  \\\n",
       "0  [0.271559052145, -0.271559052145]  [0.567475609885, 0.432524390115]   \n",
       "1  [0.271559052145, -0.271559052145]  [0.567475609885, 0.432524390115]   \n",
       "2  [0.271559052145, -0.271559052145]  [0.567475609885, 0.432524390115]   \n",
       "3  [0.271559052145, -0.271559052145]  [0.567475609885, 0.432524390115]   \n",
       "4  [0.271559052145, -0.271559052145]  [0.567475609885, 0.432524390115]   \n",
       "\n",
       "   prediction  \n",
       "0         0.0  \n",
       "1         0.0  \n",
       "2         0.0  \n",
       "3         0.0  \n",
       "4         0.0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Evaluating on CV test data Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score is : 0.999539\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Evaluate the model on the test_data (derived from the original train data)\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "score = evaluator.evaluate(predictions)\n",
    "print('Score is : %03f' % score )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions on actual test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.transform(test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score is : 0.980666\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Evaluate model\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "score = evaluator.evaluate(predictions)\n",
    "print('Score is : %03f' % score )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation & Parameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross validate results and fine tune the parameters\n",
    "from pyspark.ml.tuning import CrossValidator,ParamGridBuilder\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "grid = ParamGridBuilder(). \\\n",
    "        addGrid(lr.maxIter, [3, 5, 10]). \\\n",
    "        addGrid(lr.regParam, [0.01, 0.001, 0.0001]). \\\n",
    "        addGrid(lr.elasticNetParam, [0.1, 0.5, 1]). \\\n",
    "        build()\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=grid, evaluator=evaluator)\n",
    "cvModel = cv.fit(train_data)\n",
    "cv_score = evaluator.evaluate(cvModel.transform(test_data))\n",
    "\n",
    "best_model = cvModel.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is:0.9995476555005792\n",
      "best_reg_parameter: 0.0001\n",
      "best_max_iter: 10\n",
      "best_Elastic_Net: 0.1\n"
     ]
    }
   ],
   "source": [
    "print('best score is:' + str(cv_score))\n",
    "print('best_reg_parameter: ' + str(best_model._java_obj.getRegParam()))\n",
    "print('best_max_iter: ' + str(best_model._java_obj.getMaxIter()))\n",
    "print('best_Elastic_Net: ' + str(best_model._java_obj.getElasticNetParam()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Predicting/Evaluating on test data using the best Model from CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9795530436782655"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use cross validated parameter tuned on test set\n",
    "cv_score = evaluator.evaluate(cvModel.transform(test_new))\n",
    "cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
